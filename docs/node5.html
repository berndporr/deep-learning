<!DOCTYPE HTML>

<!--Converted with LaTeX2HTML 2021.2 (Released July 1, 2021) -->
<HTML lang="en">
<HEAD>
<TITLE>Learning rule for the single layer</TITLE>
<META NAME="description" CONTENT="Learning rule for the single layer">
<META NAME="keywords" CONTENT="deep-learning-analytics">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="viewport" CONTENT="width=device-width, initial-scale=1.0">
<META NAME="Generator" CONTENT="LaTeX2HTML v2021.2">

<LINK REL="STYLESHEET" HREF="deep-learning-analytics.css">

<LINK REL="next" HREF="node6.html">
<LINK REL="previous" HREF="node4.html">
<LINK REL="next" HREF="node6.html">
</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<A
 HREF="node6.html">
<IMG WIDTH="37" HEIGHT="24" ALT="next" SRC="next.png"></A> 
<A
 HREF="deep-learning-analytics.html">
<IMG WIDTH="26" HEIGHT="24" ALT="up" SRC="up.png"></A> 
<A
 HREF="node4.html">
<IMG WIDTH="63" HEIGHT="24" ALT="previous" SRC="prev.png"></A>   
<BR>
<B> Next:</B> <A
 HREF="node6.html">Multi-layer network: error backpropagation</A>
<B> Up:</B> <A
 HREF="deep-learning-analytics.html">Deep learning</A>
<B> Previous:</B> <A
 HREF="node4.html">Gradient descent</A>
<BR>
<BR></DIV>
<!--End of Navigation Panel-->

<H1><A ID="SECTION00050000000000000000">
Learning rule for the single layer</A>
</H1>
We can now derive the learning rule which changes the weights
<!-- MATH
 $\omega_{ji}$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 1.97ex; vertical-align: -0.72ex; " SRC="img12.svg"
 ALT="$\omega_{ji}$"></SPAN>.  We simply insert Eq.&nbsp;<A HREF="node2.html#linear_sum">2</A>,
<A HREF="node3.html#output_error">3</A> and <A HREF="node3.html#quaderr">4</A> into Eq.&nbsp;<A HREF="node4.html#graddes">5</A>:
<BR>
<DIV CLASS="displaymath"><A ID="chainrule"></A><A ID="learningrule"></A><!-- MATH
 \begin{eqnarray}
\Delta\omega_{ji}
   & = & - \mu \frac{1}{2} \frac{\partial ( d_i(n) - y_i(n) )^2 }{\partial \omega_{ji}} \\
   & = & - \mu \frac{1}{2} \frac{\partial \left( d_i(n) - \sum_j y_j(n) w_{ji} \right)^2 }{\partial \omega_{ji}} \\
  & = & \mu \underbrace{\left(d_i(n) - \sum_j y_j(n) w_{ji}\right)}_{-e_i(n)} \cdot y_j(n) \\
   & = & - \mu \underbrace{\frac{\partial E}{\partial y_i}}_{-e_i(n)} \underbrace{\frac{\partial y_i}{\partial \omega_{ji}}}_{y_j(n)}\\
  & = & \mu \cdot e_i(n) \cdot y_j(n)
\end{eqnarray}
 -->
<TABLE CELLPADDING="0" ALIGN="CENTER" WIDTH="100%">
<TR VALIGN="MIDDLE"><TD NOWRAP WIDTH="50%" ALIGN="RIGHT"><IMG
 STYLE="height: 2.53ex; vertical-align: -0.72ex; " SRC="img18.svg"
 ALT="$\displaystyle \Delta\omega_{ji}$"></TD>
<TD WIDTH="10" ALIGN="CENTER" NOWRAP><IMG
 STYLE="height: 1.18ex; vertical-align: -0.09ex; " SRC="img19.svg"
 ALT="$\displaystyle =$"></TD>
<TD ALIGN="LEFT" NOWRAP WIDTH="50%"><IMG
 STYLE="height: 5.83ex; vertical-align: -2.27ex; " SRC="img25.svg"
 ALT="$\displaystyle - \mu \frac{1}{2} \frac{\partial ( d_i(n) - y_i(n) )^2 }{\partial \omega_{ji}}$"></TD>
<TD CLASS="eqno" WIDTH=10 ALIGN="RIGHT">
(<SPAN CLASS="arabic">7</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE"><TD NOWRAP WIDTH="50%" ALIGN="RIGHT">&nbsp;</TD>
<TD WIDTH="10" ALIGN="CENTER" NOWRAP><IMG
 STYLE="height: 1.18ex; vertical-align: -0.09ex; " SRC="img19.svg"
 ALT="$\displaystyle =$"></TD>
<TD ALIGN="LEFT" NOWRAP WIDTH="50%"><IMG
 STYLE="height: 7.82ex; vertical-align: -2.27ex; " SRC="img26.svg"
 ALT="$\displaystyle - \mu \frac{1}{2} \frac{\partial \left( d_i(n) - \sum_j y_j(n) w_{ji} \right)^2 }{\partial \omega_{ji}}$"></TD>
<TD CLASS="eqno" WIDTH=10 ALIGN="RIGHT">
(<SPAN CLASS="arabic">8</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE"><TD NOWRAP WIDTH="50%" ALIGN="RIGHT">&nbsp;</TD>
<TD WIDTH="10" ALIGN="CENTER" NOWRAP><IMG
 STYLE="height: 1.18ex; vertical-align: -0.09ex; " SRC="img19.svg"
 ALT="$\displaystyle =$"></TD>
<TD ALIGN="LEFT" NOWRAP WIDTH="50%"><IMG
 STYLE="height: 10.89ex; vertical-align: -6.71ex; " SRC="img27.svg"
 ALT="$\displaystyle \mu \underbrace{\left(d_i(n) - \sum_j y_j(n) w_{ji}\right)}_{-e_i(n)} \cdot y_j(n)$"></TD>
<TD CLASS="eqno" WIDTH=10 ALIGN="RIGHT">
(<SPAN CLASS="arabic">9</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE"><TD NOWRAP WIDTH="50%" ALIGN="RIGHT">&nbsp;</TD>
<TD WIDTH="10" ALIGN="CENTER" NOWRAP><IMG
 STYLE="height: 1.18ex; vertical-align: -0.09ex; " SRC="img19.svg"
 ALT="$\displaystyle =$"></TD>
<TD ALIGN="LEFT" NOWRAP WIDTH="50%"><IMG
 STYLE="height: 9.17ex; vertical-align: -5.83ex; " SRC="img28.svg"
 ALT="$\displaystyle - \mu \underbrace{\frac{\partial E}{\partial y_i}}_{-e_i(n)} \underbrace{\frac{\partial y_i}{\partial \omega_{ji}}}_{y_j(n)}$"></TD>
<TD CLASS="eqno" WIDTH=10 ALIGN="RIGHT">
(<SPAN CLASS="arabic">10</SPAN>)</TD></TR>
<TR VALIGN="MIDDLE"><TD NOWRAP WIDTH="50%" ALIGN="RIGHT">&nbsp;</TD>
<TD WIDTH="10" ALIGN="CENTER" NOWRAP><IMG
 STYLE="height: 1.18ex; vertical-align: -0.09ex; " SRC="img19.svg"
 ALT="$\displaystyle =$"></TD>
<TD ALIGN="LEFT" NOWRAP WIDTH="50%"><IMG
 STYLE="height: 2.68ex; vertical-align: -0.72ex; " SRC="img29.svg"
 ALT="$\displaystyle \mu \cdot e_i(n) \cdot y_j(n)$"></TD>
<TD CLASS="eqno" WIDTH=10 ALIGN="RIGHT">
(<SPAN CLASS="arabic">11</SPAN>)</TD></TR>
</TABLE></DIV>
<BR CLEAR="ALL">

where <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.26ex; vertical-align: -0.53ex; " SRC="img30.svg"
 ALT="$\mu &lt;&lt; 1$"></SPAN> is the learning rate or the &ldquo;step change&rdquo;. The
learning rule Eq.&nbsp;<A HREF="#learningrule">11</A> is simply a multiplication of the
input activity <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.68ex; vertical-align: -0.72ex; " SRC="img31.svg"
 ALT="$y_j(n)$"></SPAN> with the error <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.62ex; vertical-align: -0.66ex; " SRC="img32.svg"
 ALT="$e_i(n)$"></SPAN> (<A
 HREF="node8.html#Widrow60">Widrow and Hoff, 1960</A>).

<P>
<BR><HR>
<ADDRESS>
<p><br /><a href="https://github.com/berndporr/deep-learning-analytics">github / contact</a><br /></p>
</ADDRESS>
</BODY>
</HTML>
